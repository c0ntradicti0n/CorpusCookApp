
<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<style>

span.subject1     {color: red;}
span.contrast1     {color: blue;}

span.subject2      {
    margin: 0.05em;
    padding:0.05em;
    line-height:1.2;
    display:inline-block;
    border-radius:.55em;
    border:2px solid
}
span.contrast2     {
    margin: 0.05em;
    padding:0.05em;
    line-height:1.2;
    display:inline-block;
    border-radius:.025em;
    border:2px solid
}


.indentation     {display:inline-block; 
                  width: 50px;
}
</style>
</head>
<body>
 Review   of   Logical   Foundations   of   Artificial   Intelligence   Book   Reviews   BookReviews   Automated   Reasoning   :   Thirty-Three   Basic   Research   Problems   Ulrich   <br> </br>
   Wend1   To   read   the   book   Automated   Reasoning   :   Thirty-Three   Basic   Research   Problems   (   Prentice   Hall   ,   Englewood   Cliffs   ,   N.J.   ,   1987   ,   300   pp   .   ,   $   11.00   )   by   <br> </br>
   Larry   Wos   “   it   is   not   necessary   to   be   an   expert   in   mathematics   or   logic   or   computer   science   ”   (   from   the   preface   )   .   However   ,   even   if   you   are   such   an   expert   ,   you   <br> </br>
   will   read   it   with   interest   ,   and   likely   ,   with   enjoyment   .   The   book   is   outstanding   for   its   presentation   of   the   theme   .   <br> </br>
   <br> </br>
   Following   the   introductory   chapter   ,   Wos   discusses   some   obstacles   to   the   automation   of   reasoning   in   Chapter   2   .  <span class="contrast level1 contrast1"> In </span> <span class="subject level1 subject1"> Chapter   3 </span> <span class="contrast level1 contrast1"> ,   he   lists   the   research </span>  <br> </br>
  <span class="contrast level1 contrast1"> problems   (   with   short   descriptions   )   in   nine   groups   :   six   problems   on   strategy   ,   five   on   inference   rules   ,   six   on   demodulation   ,   one   on   subsumption   ,   three   on </span>  <br> </br>
  <span class="contrast level1 contrast1"> knowledge   representation   ,   two   on   global   approach   ,   one   on   logic   programming   ,   two   on   self-analysis   ,   and   six   on   other   areas </span>  .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> After   a   short   review   of   automated   reasoning   (   AR   )   in </span> <span class="subject level1 subject1"> Chapter   4 </span> <span class="contrast level1 contrast1"> ,   these   problems   are   discussed   in   detail   in </span> <span class="subject level1 subject1"> Chapter   5 </span>  .   <br> </br>
   <span class='indentation'>  </span>  <span class="subject level1 subject1"><span class="subject level2 subject2"> Chapter   6 </span></span> <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> gives   some   sets   of   test   problems   ,   all   concerning   a   mathematical   discipline </span></span>  <br> </br>
   .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> An </span> <span class="subject level2 subject2"> appendix </span> <span class="contrast level2 contrast2"> as   interesting   as   the   bibliography   follows </span>  <br> </br>
   .   Last   but   not   least   there   is   an   excellent   index   .   The   discussion   of   the   obstacles   in   Chapter   2   is   relaxing   although   some   repetition   exists   in   the   book   ,   the   <br> </br>
   author   spares   you   a   puffy   pseudophilosophical   treatise   on   AI   in   general   and   AR   specifically   .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> After   reading   this   chapter   ,   you   are   convinced   there   is   no   general </span> <span class="subject level1 subject1"> problem   solver </span> <span class="contrast level1 contrast1"> ,   and   you   have   a   pleasant   introduction   to   the   belly   of   the   beast </span>  .  <span class="contrast level1 contrast1"> A </span>  <br> </br>
  <span class="subject level1 subject1"> non-expert </span> <span class="contrast level1 contrast1"> might   have   some   problems   in   mapping   the   eight   obstacles   described   to   the   problems   and   problem   areas   cited   earlier </span>  .   However   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> the   detailed   discussion   that   forms   the   heart   of   the   book   provides   the   reader   with   ample   reward   .   It   is   clear   that   the   author   writes   with   a   freshness   and   an </span></span>  <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> obvious   love   for   logic   .   Between   the   listing   of   the   problems   and   their   detailed   discussion   is   a   review   of </span></span> <span class="subject level2 subject2"> AR </span>  <br> </br>
   .   <br> </br>
   <br> </br>
   It   seems   to   be   too   sketchy   for   the   novice   ,   but   a   companion   book   by   the   same   author   (   Wos   ,   L.   Overbeek   ,   R.   Lusk   ,   E.   and   Boyle   ,   J.   1984   .   Automated   Reasoning   :   <br> </br>
   Introduction   and   Applications   .   Englewood   Cliffs   ,   N.J.   :   Prentice-Hall   .   )   gives   far   more   details   .   Chapter   5   ,   the   in-depth   discussion   ,   is   remarkable   for   <br> </br>
   its   style   .   It   is   fascinating   to   immerse   oneself   into   the   details   guided   more   by   questions   from   the   author   than   answers   indeed   ,   a   whole   paragraph   consists   <br> </br>
   of   nothing   but   questions   !   You   will   enjoy   this   chapter   and   the   whole   book   ,   especially   if   you   dislike   the   ‘   definition-theorem-proof   ’   style   .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> The </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> author   ’s </span> <span class="contrast level1 contrast1"> presentation </span> <span class="contrast level2 contrast2"> lets   you   forget   that   completely   solving   one   of   the   problems   is   considered   equivalent   to   finishing   a </span> <span class="subject level2 subject2"> Ph.D. </span></span>  <br> </br>
   !   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> A </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> non-expert </span></span> <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> will   have   the   most   difficulty   with   the   given   test   problems   primarily   because   they   are   all   out   of   the   field   of   mathematics   .   Again   ,   it   is   not </span></span>  <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> trivial   to   see   a   correspondence   to   the   problems   or   the   obstacles </span></span>  <br> </br>
   .   At   this   point   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> it   is   likely   the   author   ’s   opinion-“zeal   ,   interest   ,   and   curiosity   ”   suffice   as   prerequisites-is   too   optimistic </span>  <br> </br>
   .   <br> </br>
   <br> </br>
   However   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> this   book   is   also   a   workbook   ,   and  <span class="contrast level1 contrast1"> the </span> <span class="subject level1 subject1"> appendix </span> <span class="contrast level1 contrast1"> shows   the   reader   how   to   get   the   appropriate   software </span></span>  <br> </br>
   .   Finally   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> besides   a   machine   such   as   a </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> VAX </span></span> <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> ,   you   only   need   one   thing   :   a   lot   of   time </span></span>  <br> </br>
   .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> Perhaps   the   best   thing   to   say   about   the </span> <span class="subject level2 subject2"> book </span> <span class="contrast level2 contrast2"> is   that   it   tempted   me   to   wait   for   a   copy   of   the   companion   software </span>  <br> </br>
   .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> The   book   as   a   whole   is   a   rarity   in   that   it   successfully   serves   several   audiences   at   the   same   time </span>  <br> </br>
   .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> The   layperson   gets   a   real   background   knowledge   of   one   of   the   main   disciplines   of </span> <span class="subject level1 subject1"> AI </span> <span class="contrast level1 contrast1"> ,   and   the   theorist   gets   a   good   occasion   to   put   the   theory   to   practice   .   Most </span>  <br> </br>
  <span class="contrast level1 contrast1"> astonishingly   ,   both   can   enjoy   it </span>  .  <span class="contrast level1 contrast1"> One </span> <span class="subject level1 subject1"> last   point </span> <span class="contrast level1 contrast1"> is   worth   mentioning   .   It   seems   to   be   a   law   that   the   price   of   a   (   computer   science   )   book   is   inversely </span>  <br> </br>
  <span class="contrast level1 contrast1"> proportional   to   its   content   .   This   book   confirms   this   law   :   It   is   delightfully   low   priced </span>  .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> As </span> <span class="subject level1 subject1"> Georg   Christoph   Lichtenberg </span> <span class="contrast level1 contrast1"> ,   a   German   physicist   of   the   eighteenth   century   said   :   “   If   you   have   two   trousers   ,   sell   one   ,   and   buy   this   book </span>  .  <span class="contrast level1 contrast1"> ” </span> <span class="subject level1 subject1"> Ulrich   Wend1 </span> <span class="contrast level1 contrast1"> is </span>  <br> </br>
  <span class="contrast level1 contrast1"> at   the   SCS   Informationstechnik   GmbH   ,   Hoerselbergstr   .   3   ,   8000   Munchen   80 </span>  .   Logical   Foundations   of   Artificial   Intelligence   Drew   McDermott   Knowledge   is   <br> </br>
   important   to   intelligent   programs   :   Just   about   everyone   in   AI   would   agree   ,   but   the   agreement   does   n’t   extend   much   further   .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> There   is   a   weak   sense   of </span>  “   know   ”   in   which   a   computer   program   knows   P   if   its   correctness   depends   on   l   ?   For   instance   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> an </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> airline   reservation   system   might   “   know   ” </span> <span class="contrast level1 contrast1"> every   passenger </span> <span class="contrast level2 contrast2"> has   a   0.9   probability   of   showing   up   for   a   reserved   flight   in   the   sense   that   it   books   11   percent </span></span>  <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> too   many   passengers </span>  .   However   ,   more   interesting   possibilities   exist </span>  <br> </br>
   .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> A </span> <span class="subject level2 subject2"> program </span> <span class="contrast level2 contrast2"> might   have   a   notation   that   facts   can   be   expressed   ,   and   it   might   consult   a   database   of   such   facts   to   move   through   problems </span>  <br> </br>
   .   <br> </br>
   <br> </br>
   In   this   case   ,   we   have   a   more   explicit   concept   that  <span class="contrast level1 contrast1"> a   program   knows </span> <span class="subject level1 subject1"> P   if   P </span> <span class="contrast level1 contrast1"> is   in   the   database   (   or   can   be   derived   from   it   when   required   ) </span>  .   <br> </br>
   <br> </br>
   This   concept   is   the   idea   of   declarative   knowledge   the   more   mundane   concept   is   called   procedural   knowledge   .   The   book   Logical   Foundations   of   Artificial   <br> </br>
   Intelligence   (   Morgan   Kaufmann   ,   Los   Altos   ,   Calif.   ,   1987   ,   406   pp   .   ,   $   48.95   )   by   Michael   Genesereth   and   Nils   Nilsson   is   about   the   declarative   version   .   (   <br> </br>
   Declarative   knowledge   could   be   false   ,   and   we   would   do   better   to   call   it   belief   ,   as   I   often   do   in   this   review   .   )   Declarative   knowledge   requires   a   notation   ,   <br> </br>
   often   called   a   knowledge   representation   system   .   Those   who   Book   Reviews   study   declarative   knowledge   representations   are   divided   about   whether   such   <br> </br>
   notations   ought   to   be   thought   of   as   variants   of   the   predicate   calculus   and   related   systems   of   mathematical   logic   invented   by   logicians   ,   mathematicians   ,   <br> </br>
   and   philosophers   in   this   century   .   <br> </br>
   <br> </br>
   Lately   ,   those   who   think   they   ought   to   be   so   regarded   seem   to   be   winning   .   Genesereth   and   Nilsson   have   no   doubt   and   take   it   for   granted   that   the   semantic   tools   <br> </br>
   of   mathematical   logic   are   indispensable   for   analyzing   knowledge   representations   .   They   adopt   the   label   Iogicism   for   this   doctrine   .   In   Chapter   2   ,   they   <br> </br>
   develop   these   tools   from   the   point   of   view   of   AI   ,   which   is   rather   different   from   the   logician   ’s   point   of   view   .   They   introduce   the   idea   of   conceptualization   <br> </br>
   ,   which   is   roughly   what   a   philosopher   calls   the   intended   model   of   a   formal   theory   .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> A </span> <span class="subject level1 subject1"> formal   theory </span> <span class="contrast level1 contrast1"> provides   predicates   and   functions   for   talking   about   (   some   part   of   )   the   world   and   axioms   involving   these   symbols </span>  .  <span class="subject level1 subject1"> Formal   semantics </span>  <br> </br>
  <span class="contrast level1 contrast1"> specifies   a   mapping   from   the   symbols   to   the   entities   in   the   world </span>  .   It   is   one   of   the   key   insights   (   and   disturbing   insights   )   of   mathematical   logic   that   unique   <br> </br>
   mappings   are   rare   .   Any   given   theory   has   many   interpretations   that   make   its   axioms   true   ,   that   is   ,   several   models   .   Mathematicians   cheerfully   study   them   <br> </br>
   all   ,   but   philosophers   worry   more   about   how   the   correct   model   can   be   picked   out   .   <br> </br>
   <br> </br>
   Fortunately   ,   in   AI   ,   we   can   ignore   these   problems   and   treat   ontological   commitment   as   an   engineering   decision   .   It   does   n’t   matter   that   the   robot   we   build   <br> </br>
   can   not   intend   a   model   its   builders   can   .   Genesereth   and   Nilsson   give   a   lucid   explanation   of   this   topic   .   When   they   reach   the   topic   of   inference   ,   however   ,   <br> </br>
   they   seem   to   lose   their   way   .   Chapters   3   through   5   are   concerned   with   this   topic   ,   but   it   is   central   to   the   entire   book   .   Inference   can   be   considered   as   the   <br> </br>
   deriving   of   probably   useful   ,   probably   correct   conclusions   from   a   set   of   beliefs   .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> This </span> <span class="contrast level1 contrast1"> characterization   is   vague </span>  ,   but  <span class="contrast level1 contrast1"> the </span> <span class="subject level1 subject1"> vagueness </span> <span class="contrast level1 contrast1"> is   inevitable </span>  .   Almost   any   algorithm   can   be   thought   of   as   doing   inference   in   some   sense   ,   and   if   we   arrange   <br> </br>
   that   its   premises   and   conclusions   are   expressed   in   a   logical   notation   (   not   a   difficult   requirement   )   ,   then   it   can   be   thought   of   as   doing   inference   on   a   <br> </br>
   declarative   knowledge   representation   .   The   authors   give   several   examples   throughout   the   book   .   Chapter   7   ,   for   instance   ,   is   devoted   to   concept   learning   ,   <br> </br>
   in   which   new   rules   are   inferred   from   facts   that   would   follow   from   them   .   The   algorithms   described-based   on   Tom   Mitchell   ’s   idea   of   version   spaces-are   <br> </br>
   specific   to   the   domain   of   the   concept   of   learning   .   <br> </br>
   <br> </br>
   Similarly   ,  <span class="subject level1 subject1"> Chapter   8 </span> <span class="contrast level1 contrast1"> describes   Bayesian   inference   ,   from   a   priori   probabilities   to   a   posteriori   probabilities   given   new   evidence </span>  .  <span class="contrast level1 contrast1"> In   competition   with </span>  <br> </br>
  <span class="contrast level1 contrast1"> this </span> <span class="subject level1 subject1"> diversity </span> <span class="contrast level1 contrast1"> is   the   idea   of   a   unified   model   of   inference </span>  .   The   desire   for   such   a   model   is   strong   among   those   who   study   declarative   representations   ,   and   <br> </br>
   Genesereth   and   Nilsson   are   no   exception   .   As   are   most   of   their   colleagues   ,   they   are   drawn   to   the   model   of   inference   as   the   derivation   of   conclusions   that   are   <br> </br>
   entailed   by   a   set   of   beliefs   .   <br> </br>
   <br> </br>
   They   wander   from   this   idea   in   a   few   places   but   not   for   long   .   It   is   not   hard   to   see   why   :   Deduction   is   one   of   the   fews   kinds   of   inference   for   which   we   have   an   <br> </br>
   interesting   general   theory   .   The   authors   made   a   conscious   decision   not   to   talk   much   about   search   processes   .   Unfortunately   ,   a   deductive   process   is   always   <br> </br>
   confronted   with   the   problem   of   what   to   deduce   next   it   is   impossible   to   correctly   choose   with   any   confidence   ,   so   programs   that   deduce   must   try   various   <br> </br>
   options   .   Sometimes   ,   they   can   generate   many   useless   inferences   before   finding   useful   ones   .   <br> </br>
   <span class='indentation'>  </span>  <span class="subject level2 subject2"> Chapters </span> <span class="contrast level2 contrast2"> 4   and   5   are   devoted   to   the   topic   of   implementing   deductive   processes   using   the   resolution   method   with   various   refinement   strategies </span>  <br> </br>
   .   However   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> throughout   the   rest   of   the   book </span>  <br> </br>
   ,  <span class="contrast level1 contrast1"> little </span> <span class="subject level1 subject1"> focus </span> <span class="contrast level1 contrast1"> is   given   to   the   actual   computational   consequences   of   relying   on   these   methods </span>  .   Usually   ,  <span class="subject level1 subject1"> proofs </span> <span class="contrast level1 contrast1"> are   given   with   a   passing   warning   that </span>  <br> </br>
  <span class="contrast level1 contrast1"> finding   the   proof   might   be   expensive </span>  .   <br> </br>
   <br> </br>
   It   ’s   clear   what   the   authors   are   thinking   .   They   are   studying   foundations   so   ,   what   ’s   important   is   what   should   be   inferred   in   a   situation   ,   not   what   actually   <br> </br>
   can   be   practically   inferred   (   compared   ,   say   ,   to   theoretical   mechanics   )   .   However   ,   as   I   argued   earlier   ,   what   should   be   inferred   is   probably   different   from   <br> </br>
   what   is   entailed   by   current   beliefs   because   not   all   that   is   entailed   is   useful   and   not   all   that   is   probably   correct   is   entailed   .   The   authors   are   forced   to   <br> </br>
   acknowledge   these   discrepancies   in   their   detours   to   alternative   inference   techniques   in   Chapters   6   ,   7   ,   and   8   ,   but   their   heart   is   n’t   in   it   .   <br> </br>
   <br> </br>
   When   it   comes   to   actual   applications   ,   they   always   revert   to   classical   deduction   .   The   unsophisticated   reader   should   be   warned   that   the   foundations   being   <br> </br>
   explored   are   not   exactly   the   foundations   of   AI   .   The   authors   ’   viewpoint   causes   distortions   throughout   the   book   .   The   chapter   on   planning   (   Chapter   12   )   is   <br> </br>
   typical   .   The   planning   problem   is   defined   as   finding   a   constructive   proof   that   a   series   of   actions   will   bring   about   a   desired   state   of   the   world   .   It   is   <br> </br>
   assumed   that   the   right   way   to   find   this   proof   is   to   tailor   a   general-purpose   theorem   prover   with   a   few   specialized   strategies   .   <br> </br>
   <br> </br>
   This   description   of   the   planning   problem   is   quite   remote   from   any   description   that   active   researchers   in   the   field   would   produce   .   Perhaps   Genesereth   and   <br> </br>
   Nilsson   feel   that   techniques   for   solving   planning   problems   will   come   and   go   ,   but   the   foundations   can   be   secure   .   If   so   ,   they   are   too   casual   about   the   <br> </br>
   implicit   claim   .   I   admit   to   bias   on   these   questions   .   My   skepticism   should   be   balanced   by   the   agreement   of   many   perfectly   reasonable   people   with   Genesereth   <br> </br>
   and   Nilsson   ’s   view   .   However   ,   it   bothers   me   that   questions   about   the   scope   of   their   enterprise   are   treated   so   superficially   in   this   book   .   <br> </br>
   <br> </br>
   Let   me   put   such   doubts   aside   and   pretend   from   now   on   that   deduction   is   the   foundation   of   AI   .   Within   this   perspective   ,  <span class="contrast level1 contrast1"> the </span> <span class="subject level1 subject1"> book </span> <span class="contrast level1 contrast1"> has   some   strengths   and   some </span>  <br> </br>
  <span class="contrast level1 contrast1"> weaknesses </span>  .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> Chapter   6 </span> <span class="contrast level1 contrast1"> is   an   excellent   discussion   of   nonmonotonic   logic   ,   a   family   of   logic   extensions   that   allow   defeasible   conclusions   ,   which   can   be   blocked   by </span>  <br> </br>
  <span class="contrast level1 contrast1"> knowing   more </span>  .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> Most   real-world   inference   is </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> nonmonotonic </span></span> <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> because   knowing   more   usually   causes   one   to   change   one   ’s   mind   in   some   way </span></span>  <br> </br>
   .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> For   example   ,   if   told   that   person   P   is   an   adult   living   in   suburbia   ,   you   would   probably   infer </span> <span class="subject level2 subject2"> P </span> <span class="contrast level2 contrast2"> owns   a   car </span>  <br> </br>
   .   Now   ,   suppose   the   further   information   that   P   is   blind   .   <br> </br>
   <br> </br>
   It   is   a   problem   with   the   logicist   approach   to   infer   that  <span class="subject level1 subject1"> logic </span> <span class="contrast level1 contrast1"> lacks   this   ability </span>  if  <span class="contrast level1 contrast1"> a </span> <span class="subject level1 subject1"> proposition </span> <span class="contrast level1 contrast1"> is   entailed   by   a   set   of   beliefs   ,   it   is   entailed   by   any </span>  <br> </br>
  <span class="contrast level1 contrast1"> superset </span>  .   Various   nonmonotonic   variants   of   logic   have   been   proposed   .   They   are   all   covered   in   Chapter   6   ,   especially   John   McCarthy   ’s   circumscription   ,   <br> </br>
   which   augments   a   standard   theory   with   a   special   axiom   schema   that   can   change   nonmonotonically   as   new   beliefs   are   added   .   This   description   of   <br> </br>
   circumscription   is   the   best   I   have   seen   no   one   could   ask   for   more   from   a   textbook   .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> Chapter   7 </span> <span class="contrast level1 contrast1"> ,   on   induction   ,   is   too   short </span>  .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> Induction </span> <span class="contrast level1 contrast1"> is   defined   as   the   Book   Reviews   Response   to   Drew   McDermott   ’s   Review   of   Logical   Foundations   of   Artificial   Intelligence   problem   of   finding   a </span>  <br> </br>
  <span class="contrast level1 contrast1"> hypothesis   that   entails   observed   data </span>  .   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> An </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> excellent   description </span></span> <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> follows   of   version   spaces   ,   a   useful   framework   for   thinking   about   sets   of   hypotheses   that   have   not   been   ruled   out   by   data </span></span>  <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> observed   so   far </span></span>  <br> </br>
   .   However   ,   <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level2 contrast2"> no </span> <span class="subject level2 subject2"> mention </span> <span class="contrast level2 contrast2"> is   made   of   Ehud   Shapiro   ’s   or   Gordon   Plotkin   ’s   generalizations   of   the   idea   to   a   logical   framework   ,   which   is   an   amazing   omission </span>  <br> </br>
   .   <br> </br>
   <br> </br>
   It   would   have   been   nice   to   see   a   discussion   of   explanation-based   generalization   ,   a   more   recent   idea   of   Mitchell   ’s   in   which   a   problem   solution   ,   expressed   <br> </br>
   as   a   proof   ,   is   generalized   and   stored   as   a   new   lemma   .   Perhaps   ,   this   idea   is   too   recent   ,   but   it   would   fit   the   authors   ’   world   view   well   .   Chapter   8   ,   on   <br> </br>
   probabilities   ,   is   weaker   .   It   deals   with   two   topics   ,   with   little   hint   about   how   they   are   related   or   how   much   of   the   problem   of   reasoning   under   uncertainty   is   <br> </br>
   covered   .   The   first   topic   is   Bayesian   inference   ,   which   underlies   much   work   on   expert   systems   .   <br> </br>
   <br> </br>
   The   discussion   is   clear   and   helpful   .   The   second   topic   is   Nilsson   ’s   probabilistic   logic   ,   an   attempt   to   generalize   logical   entailment   so   that   the   <br> </br>
   probability   of   a   conclusion   can   be   found   given   the   probabilities   of   some   premises   .   It   is   not   clear   what   the   theoretical   or   practical   significance   of   <br> </br>
   probabilistic   logic   is   .  <span class="contrast level1 contrast1"> The </span> <span class="subject level1 subject1"> maximum-entropy </span> <span class="contrast level1 contrast1"> method   is   briefly   mentioned   here   I   wish   it   had   been   covered   in   more   depth   because   it   is   of   interest   in   its   own </span>  <br> </br>
  <span class="contrast level1 contrast1"> right </span>  .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> Chapter   9 </span> <span class="contrast level1 contrast1"> is   a   description   of   the   logic   of   knowledge   and   belief   using   two   different   conceptualizations   :   Kurt   Konolige   ’s   syntactic   approach   and   J.K.K. </span>  <br> </br>
  <span class="contrast level1 contrast1"> Hintikka   ’s   possible   worlds   approach   .   This   discussion   is   lucid   and   thorough </span>  .   <br> </br>
   <br> </br>
   In   the   syntactic   approach   ,   belief   is   a   predicate   on   formulas   in   an   agent   ’s   database   .  <span class="contrast level1 contrast1"> In   the   possible   worlds   approach   ,   an   agent   does   not   believe   P   if   for   all </span>  <br> </br>
  <span class="contrast level1 contrast1"> the   agent   knows   ,   P   might   be   false   and   this   statement   is   formalized   as   “   There   exists   a   world   ,   possible   as   far   as   the   agent   believes   ,   in   which   P   is   false </span>  .   <br> </br>
   <br> </br>
   ”   In   either   approach   ,   we   can   make   inferences   such   as   “   If   Fred   knows   that   Mary   ’s   phone   number   is   the   same   as   John   ’s   ,   and  <span class="contrast level1 contrast1"> he   knows   Mary   ’s   phone   number   ,   then   he </span>  <br> </br>
  <span class="contrast level1 contrast1"> knows   John   ’s   ”   without   knowing   what   the   phone   number   is </span>  .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> Chapter   10 </span> <span class="contrast level1 contrast1"> is   about   metareasoning   ,   or   reasoning   about   reasoning   .   This   concept   mesmerizes   many   in   AI   ,   probably   because   it   seems   intimately   connected </span>  <br> </br>
  <span class="contrast level1 contrast1"> with   our   ability   to   consciously   introspect   and   observe   ourselves   thinking </span>  .   However   ,  <span class="contrast level1 contrast1"> except   for   this   connection   , </span>  <br> </br>
   <span class='indentation'>  </span>  <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> the   value   of </span></span> <span class="subject level1 subject1"><span class="subject level2 subject2"> metareasoning </span></span> <span class="contrast level1 contrast1"><span class="contrast level2 contrast2"> as   a   programming   or   representation   technique   has   seldom   been   demonstrated </span></span>  <br> </br>
   .   <br> </br>
   <span class='indentation'>  </span>  <span class="subject level2 subject2"> Chapter   10 </span> <span class="contrast level2 contrast2"> is   mainly   concerned   with   pointing   out   various   alternative   architectures   for   metareasoning </span>  <br> </br>
   .   <br> </br>
   <br> </br>
   Little   discussion   is   given   of   what   it   is   for   .  <span class="contrast level1 contrast1"> One </span> <span class="subject level1 subject1"> possibility </span> <span class="contrast level1 contrast1"> is   for   reasoning   about   the   reasoning   of   other   agents   ,   which   connects   to   the   syntactic   belief </span>  <br> </br>
  <span class="contrast level1 contrast1"> calculus   of   Chapter   9 </span>  .   However   ,  <span class="contrast level1 contrast1"> the </span> <span class="subject level1 subject1"> possibility </span> <span class="contrast level1 contrast1"> is   not   really   explored   ,   except   for   a   baffling   detour   into   an   alternative   formalization   of   belief   that   is </span>  <br> </br>
  <span class="contrast level1 contrast1"> never   related   to   the   approaches   of   Chapter   9 </span>  .   Chapters   11   and   12   are   about   temporal   reasoning   and   planning   .   They   are   out   of   date   ,   based   on   the   situation   <br> </br>
   calculus   devised   by   John   McCarthy   and   Patrick   Hayes   in   the   late   1960s   .   <br> </br>
   <br> </br>
  <span class="contrast level1 contrast1"> A   lot   of   work   has   been   done   in   the   last   20   years   in   the   logicist   tradition   on   formalizing   temporal   reasoning   to   handle   continuous   time   and   alternative </span>  <br> </br>
  <span class="contrast level1 contrast1"> possible   worlds   .   It   is   mentioned   only   in   the   bibliographic   notes </span>  .  <span class="subject level1 subject1"> Chapter   13 </span> <span class="contrast level1 contrast1"> is   entitled   IntelligentAgent   Architecture   ,   but   it   is   nothing   of   the   sort </span>  .   It   <br> </br>
   is   hard   to   say   what   it   is   about   .   <br> </br>
   <br> </br>
   I   think   it   was   meant   to   be   a   nod   toward   robotics   .   In   summary   ,   this   book   has   some   excellent   parts   ,   notably   its   treatments   of   formal   semantics   ,   nonmonotonic   <br> </br>
   logic   ,   and   logics   of   knowledge   and   belief   .   However   ,  <span class="contrast level1 contrast1"> it   omits   detailed   discussion   of   the   work   of   many   logicists   ,   including   James   Allen   ,   Alan   Bundy   ,   Ernie </span>  <br> </br>
  <span class="contrast level1 contrast1"> Davis   ,   Patrick   Hayes   ,   Robert   Kowalski   ,   Ray   Reiter   ,   and   Udi   Shapiro </span>  .   <br> </br>
   <br> </br>
  <span class="subject level1 subject1"> Opportunities </span> <span class="contrast level1 contrast1"> were   missed   for   tracing   a   consistent   thread   through   the   topics   covered </span>  .   <br> </br>
   <br> </br>
   Nonmonotonic   reasoning   is   rarely   mentioned   after   Chapter   6   ,   even   though   it   is   relevant   in   several   subsequent   chapters   .   Reasoning   about   reasoning   is   <br> </br>
   covered   in   Chapters   9   ,   10   ,   and   13   ,   each   time   from   a   different   perspective   .   Finally   ,   the   book   is   unself-conscious   about   the   importance   of   logic   in   AI   ,   which   <br> </br>
   might   be   less   than   the   authors   believe   .   Nils   Nilsson   McDermott   makes   some   valid   points   in   his   review   .   I   acknowledge   some   of   these   in   this   response   .   It   ’s   too   <br> </br>
   bad   that   he   chose   to   embed   the   helpful   comments   in   the   context   of   his   bynow-tiresome   doubts   about   the   value   of   logic   in   AI   .   <br> </br>
   <br> </br>
   (   The   reader   who   wants   to   be   saturated   with   the   arguments   surrounding   these   doubts   should   see   McDermott   ’s   1977   A   Critique   of   Pure   Reason   and   the   <br> </br>
   accompanying   commentary   in   Computational   Intelligence   ,   3(3   )   .   McDermott   accurately   summarizes   our   book   as   being   about   the   representation   and   use   of   <br> </br>
   declarative   knowledge   in   AI   .   He   duly   notes   that   declarative   knowledge   requires   a   notation   and   that   some   AI   researchers   think   most   of   the   notational   <br> </br>
   schemes   being   used   are   variants   of   the   predicate   calculus   .   He   even   says   ,   “   Lately   those   who   think   they   ought   to   be   so   regarded   seem   to   be   winning   .   <br> </br>
   <br> </br>
   ”   Under   these   circumstances   ,  <span class="contrast level1 contrast1"> it   does   seem   odd   for </span> <span class="subject level1 subject1"> McDermott </span> <span class="contrast level1 contrast1"> to   devote   much   space   to   complaining   about   the   logical   basis   of   a   book   whose   very   title   proclaims </span>  <br> </br>
  <span class="contrast level1 contrast1"> it   is   about   logical   foundations </span>  .   <br> </br>
   <br> </br>
   In   any   case   ,   given   such   a   title   ,   it   would   n’t   seem   necessary   that   readers   “   should   be   warned   that   the   foundations   being   explored   are   not   exactly   the   <br> </br>
   foundations   of   [   all   of   ]   AI   .   ”   It   seems   one   of   McDermott   ’s   main   complaints   about   the   logical   approach   is   based   on   his   view   that   “   logicists   ”   think   of   <br> </br>
   inference   as   being   simply   sound   deductive   inference   .   Actually   ,   we   happen   to   agree   with   McDermott   ’s   statement   that   “   almost   any   algorithm   can   be   thought   <br> </br>
   of   as   doing   inference   in   some   sense   ,   and   if   we   arrange   that   its   premises   and   conclusions   are   expressed   in   a   logical   notation   (   not   a   difficult   requirement   )   ,   <br> </br>
   then   it   can   be   thought   of   as   doing   inference   on   a   declarative   knowledge   representation   .   <br> </br>
   <br> </br>
   ”   He   inappropriately   and   unfairly   characterizes   our   treatment   of   various   nondeductive   inference   techniques   (   nonmonotonic   reasoning   ,   inductive   <br> </br>
   reasoning   ,   and   probabilistic   reasoning   )   as   mere   detours   from   what   he   would   like   to   regard   as   our   commitment   to   deductive   inference   .   We   had   hoped   it   would   <br> </br>
   be   obvious   that   our   commitment   regarding   inference   is   n’t   exclusively   Book   Reviews   Have   KEE”-   Will   Travel   KEE   is   a   registered   trademark   of   IntelliCorp   <br> </br>
   Knowledge-Based   Systems   AMOS   OSHRIN   Knowledge   Systems   Consultant   RESULTS   ,   Not   Just   Reports   This   publication   is   available   in   microform   from   <br> </br>
   University   1   Please   send   information   about   these   titles   :   Name   CompanyInstitution   Address   City   state   Zip   Phone   1   I   For   free   information   ,   circle   no.   101   to   <br> </br>
   soundness   but   to   an   understanding   of   the   underlying   theoretical   properties   of   various   inference   methods   . 
</body>
</html>
